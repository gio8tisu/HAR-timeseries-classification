{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dataset import HARDatasetCrops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = HARDatasetCrops('motionsense-dataset/train', 256, 50, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 4095\n",
      "Datapoints shape: (256, 12)\n"
     ]
    }
   ],
   "source": [
    "print('Dataset size:', len(dataset))\n",
    "\n",
    "sample, _ = dataset[0]\n",
    "print('Datapoints shape:', sample.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset is composed of 5205 datapoints, each have shape `(256, 12)` because we have 12 signals of 256 samples each."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our base line model we will use the **user-acceleration**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dataset = HARDatasetCrops('motionsense-dataset/train', 256, 50, 50, metadata_file='motionsense-dataset/data_subjects_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([sample[:,-3:] for sample, _, _ in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = np.array([metadata for _, _, metadata in dataset])\n",
    "metadata = metadata.reshape((-1, 4, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to fit a `sklearn` model we should encode each class with a unique integer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoder.fit(list(dataset.CLASSES.keys()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "y = to_categorical(label_encoder.transform([cls for _, cls in dataset]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-test splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "indices = np.random.choice(np.arange(X.shape[0]), X.shape[0], replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = indices[:int(X.shape[0] * 0.8)]\n",
    "test_indices = indices[int(X.shape[0] * 0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_test, y_test = X[test_indices], y[test_indices]\n",
    "metadata_train = metadata[train_indices]\n",
    "metadata_test = metadata[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: {} (3276, 256, 3)\n",
      "y train shape: {} (3276, 6)\n",
      "X test shape: {} (819, 256, 3)\n",
      "y test shape: {} (819, 6)\n",
      "metdata train shape: {} (3276, 4, 1)\n",
      "metdata test shape: {} (819, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: {}\", X_train.shape)\n",
    "print(\"y train shape: {}\", y_train.shape)\n",
    "print(\"X test shape: {}\", X_test.shape)\n",
    "print(\"y test shape: {}\", y_test.shape)\n",
    "print(\"metdata train shape: {}\", metadata_train.shape)\n",
    "print(\"metdata test shape: {}\", metadata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 3276\n",
      "Number of testing examples: 819\n"
     ]
    }
   ],
   "source": [
    "print('Number of training examples:', y_train.shape[0])\n",
    "print('Number of testing examples:', y_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, Flatten, concatenate, Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "clf = Sequential()\n",
    "#add model layers\n",
    "clf.add(Conv1D(16, kernel_size=5, activation=\"relu\", input_shape=(256, 3)))\n",
    "clf.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
    "clf.add(Flatten())\n",
    "clf.add(Dense(6, activation=\"softmax\", kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 819 samples\n",
      "Epoch 1/30\n",
      "3276/3276 [==============================] - 1s 392us/step - loss: 1.1588 - accuracy: 0.5607 - val_loss: 0.8419 - val_accuracy: 0.7131\n",
      "Epoch 2/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.7115 - accuracy: 0.7579 - val_loss: 0.7180 - val_accuracy: 0.7521\n",
      "Epoch 3/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.6017 - accuracy: 0.8053 - val_loss: 0.7178 - val_accuracy: 0.7582\n",
      "Epoch 4/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.5390 - accuracy: 0.8303 - val_loss: 0.6707 - val_accuracy: 0.7827\n",
      "Epoch 5/30\n",
      "3276/3276 [==============================] - 1s 268us/step - loss: 0.5076 - accuracy: 0.8404 - val_loss: 0.7111 - val_accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.4931 - accuracy: 0.8452 - val_loss: 0.6275 - val_accuracy: 0.8230\n",
      "Epoch 7/30\n",
      "3276/3276 [==============================] - 1s 262us/step - loss: 0.4672 - accuracy: 0.8623 - val_loss: 0.5994 - val_accuracy: 0.8071\n",
      "Epoch 8/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.4491 - accuracy: 0.8614 - val_loss: 0.6473 - val_accuracy: 0.8132\n",
      "Epoch 9/30\n",
      "3276/3276 [==============================] - 1s 280us/step - loss: 0.4263 - accuracy: 0.8709 - val_loss: 0.5691 - val_accuracy: 0.8400\n",
      "Epoch 10/30\n",
      "3276/3276 [==============================] - 1s 269us/step - loss: 0.4021 - accuracy: 0.8883 - val_loss: 0.5817 - val_accuracy: 0.8059\n",
      "Epoch 11/30\n",
      "3276/3276 [==============================] - 1s 270us/step - loss: 0.3839 - accuracy: 0.8935 - val_loss: 0.6184 - val_accuracy: 0.8254\n",
      "Epoch 12/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.3856 - accuracy: 0.8849 - val_loss: 0.5681 - val_accuracy: 0.8254\n",
      "Epoch 13/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3595 - accuracy: 0.9026 - val_loss: 0.6096 - val_accuracy: 0.8364\n",
      "Epoch 14/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3580 - accuracy: 0.8944 - val_loss: 0.6040 - val_accuracy: 0.8474\n",
      "Epoch 15/30\n",
      "3276/3276 [==============================] - 1s 274us/step - loss: 0.3484 - accuracy: 0.9133 - val_loss: 0.5792 - val_accuracy: 0.8266\n",
      "Epoch 16/30\n",
      "3276/3276 [==============================] - 1s 271us/step - loss: 0.3616 - accuracy: 0.9005 - val_loss: 0.6682 - val_accuracy: 0.8144\n",
      "Epoch 17/30\n",
      "3276/3276 [==============================] - 1s 267us/step - loss: 0.3576 - accuracy: 0.9106 - val_loss: 0.5363 - val_accuracy: 0.8474\n",
      "Epoch 18/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.3303 - accuracy: 0.9154 - val_loss: 0.5681 - val_accuracy: 0.8474\n",
      "Epoch 19/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3235 - accuracy: 0.9185 - val_loss: 0.5121 - val_accuracy: 0.8706\n",
      "Epoch 20/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.2961 - accuracy: 0.9277 - val_loss: 0.4885 - val_accuracy: 0.8755\n",
      "Epoch 21/30\n",
      "3276/3276 [==============================] - 1s 275us/step - loss: 0.2992 - accuracy: 0.9261 - val_loss: 0.5397 - val_accuracy: 0.8510\n",
      "Epoch 22/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.2949 - accuracy: 0.9261 - val_loss: 0.5308 - val_accuracy: 0.8645\n",
      "Epoch 23/30\n",
      "3276/3276 [==============================] - 1s 277us/step - loss: 0.2796 - accuracy: 0.9365 - val_loss: 0.5290 - val_accuracy: 0.8669\n",
      "Epoch 24/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.2738 - accuracy: 0.9374 - val_loss: 0.5396 - val_accuracy: 0.8584\n",
      "Epoch 25/30\n",
      "3276/3276 [==============================] - 1s 276us/step - loss: 0.3281 - accuracy: 0.9161 - val_loss: 0.5239 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "3276/3276 [==============================] - 1s 271us/step - loss: 0.2905 - accuracy: 0.9393 - val_loss: 0.4680 - val_accuracy: 0.8840\n",
      "Epoch 27/30\n",
      "3276/3276 [==============================] - 1s 267us/step - loss: 0.2673 - accuracy: 0.9441 - val_loss: 0.4866 - val_accuracy: 0.8547\n",
      "Epoch 28/30\n",
      "3276/3276 [==============================] - 1s 265us/step - loss: 0.2501 - accuracy: 0.9475 - val_loss: 0.5122 - val_accuracy: 0.8694\n",
      "Epoch 29/30\n",
      "3276/3276 [==============================] - 1s 265us/step - loss: 0.2581 - accuracy: 0.9389 - val_loss: 0.4931 - val_accuracy: 0.8669\n",
      "Epoch 30/30\n",
      "3276/3276 [==============================] - 1s 273us/step - loss: 0.2725 - accuracy: 0.9350 - val_loss: 0.4698 - val_accuracy: 0.8742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x143f97350>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       1.00      0.99      0.99       284\n",
      "         jog       1.00      1.00      1.00       307\n",
      "         sit       0.87      0.97      0.91       794\n",
      "         std       0.96      0.84      0.89       726\n",
      "         ups       0.99      1.00      0.99       343\n",
      "         wlk       1.00      0.99      0.99       822\n",
      "\n",
      "    accuracy                           0.95      3276\n",
      "   macro avg       0.97      0.96      0.96      3276\n",
      "weighted avg       0.96      0.95      0.95      3276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(clf.predict(X_train), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.81      0.77      0.79        75\n",
      "         jog       0.96      0.95      0.95        77\n",
      "         sit       0.89      0.94      0.92       210\n",
      "         std       0.91      0.86      0.89       174\n",
      "         ups       0.76      0.69      0.72        93\n",
      "         wlk       0.86      0.91      0.88       190\n",
      "\n",
      "    accuracy                           0.87       819\n",
      "   macro avg       0.87      0.85      0.86       819\n",
      "weighted avg       0.87      0.87      0.87       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(clf.predict(X_test), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "conv = Sequential()\n",
    "# add model layers\n",
    "conv.add(Conv1D(16, kernel_size=5, activation=\"relu\", input_shape=(256, 3)))\n",
    "conv.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
    "conv.add(Flatten(name=\"coefs\"))\n",
    "\n",
    "metadata_input_tensor = Input(shape=(4, 1))\n",
    "metadata_input = Flatten(name=\"flatten\")(metadata_input_tensor)\n",
    "\n",
    "last_layer = conv.get_layer(\"coefs\").output\n",
    "x = concatenate([last_layer, metadata_input], axis=1)\n",
    "out = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "clf = Model([conv.input, metadata_input_tensor], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 819 samples\n",
      "Epoch 1/30\n",
      "3276/3276 [==============================] - 1s 374us/step - loss: 0.9303 - accuracy: 0.6242 - val_loss: 0.6766 - val_accuracy: 0.7436\n",
      "Epoch 2/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.5016 - accuracy: 0.7866 - val_loss: 0.5411 - val_accuracy: 0.7753\n",
      "Epoch 3/30\n",
      "3276/3276 [==============================] - 1s 307us/step - loss: 0.3788 - accuracy: 0.8483 - val_loss: 0.5021 - val_accuracy: 0.8010\n",
      "Epoch 4/30\n",
      "3276/3276 [==============================] - 1s 302us/step - loss: 0.2967 - accuracy: 0.8886 - val_loss: 0.4907 - val_accuracy: 0.8291\n",
      "Epoch 5/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.2517 - accuracy: 0.9106 - val_loss: 0.4769 - val_accuracy: 0.8535\n",
      "Epoch 6/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.2101 - accuracy: 0.9216 - val_loss: 0.4639 - val_accuracy: 0.8474\n",
      "Epoch 7/30\n",
      "3276/3276 [==============================] - 1s 311us/step - loss: 0.1692 - accuracy: 0.9426 - val_loss: 0.4234 - val_accuracy: 0.8632\n",
      "Epoch 8/30\n",
      "3276/3276 [==============================] - 1s 308us/step - loss: 0.1367 - accuracy: 0.9554 - val_loss: 0.4549 - val_accuracy: 0.8718\n",
      "Epoch 9/30\n",
      "3276/3276 [==============================] - 1s 317us/step - loss: 0.1263 - accuracy: 0.9606 - val_loss: 0.4667 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "3276/3276 [==============================] - 1s 320us/step - loss: 0.1088 - accuracy: 0.9631 - val_loss: 0.4835 - val_accuracy: 0.8718\n",
      "Epoch 11/30\n",
      "3276/3276 [==============================] - 1s 316us/step - loss: 0.0996 - accuracy: 0.9667 - val_loss: 0.5491 - val_accuracy: 0.8584\n",
      "Epoch 12/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 0.4904 - val_accuracy: 0.8730\n",
      "Epoch 13/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0836 - accuracy: 0.9698 - val_loss: 0.4876 - val_accuracy: 0.8730\n",
      "Epoch 14/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.5143 - val_accuracy: 0.8669\n",
      "Epoch 15/30\n",
      "3276/3276 [==============================] - 1s 317us/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.5318 - val_accuracy: 0.8755\n",
      "Epoch 16/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 0.5435 - val_accuracy: 0.8742\n",
      "Epoch 17/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0583 - accuracy: 0.9814 - val_loss: 0.5484 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 0.6054 - val_accuracy: 0.8718\n",
      "Epoch 19/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.0557 - accuracy: 0.9805 - val_loss: 0.6509 - val_accuracy: 0.8742\n",
      "Epoch 20/30\n",
      "3276/3276 [==============================] - 1s 321us/step - loss: 0.0832 - accuracy: 0.9731 - val_loss: 0.5975 - val_accuracy: 0.8755\n",
      "Epoch 21/30\n",
      "3276/3276 [==============================] - 1s 313us/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 0.7383 - val_accuracy: 0.8596\n",
      "Epoch 22/30\n",
      "3276/3276 [==============================] - 1s 310us/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.5572 - val_accuracy: 0.8730\n",
      "Epoch 23/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.5575 - val_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "3276/3276 [==============================] - 1s 307us/step - loss: 0.0498 - accuracy: 0.9820 - val_loss: 0.5860 - val_accuracy: 0.8840\n",
      "Epoch 25/30\n",
      "3276/3276 [==============================] - 1s 319us/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.5857 - val_accuracy: 0.8828\n",
      "Epoch 26/30\n",
      "3276/3276 [==============================] - 1s 308us/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.6012 - val_accuracy: 0.8877\n",
      "Epoch 27/30\n",
      "3276/3276 [==============================] - 1s 345us/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.6133 - val_accuracy: 0.8877\n",
      "Epoch 28/30\n",
      "3276/3276 [==============================] - 1s 315us/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.6123 - val_accuracy: 0.8828\n",
      "Epoch 29/30\n",
      "3276/3276 [==============================] - 1s 314us/step - loss: 0.0371 - accuracy: 0.9850 - val_loss: 0.6443 - val_accuracy: 0.8852\n",
      "Epoch 30/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 0.6552 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x122d27d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit([X_train, metadata_train], y_train, validation_data=([X_test, metadata_test], y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       1.00      1.00      1.00       284\n",
      "         jog       1.00      1.00      1.00       307\n",
      "         sit       0.97      0.99      0.98       794\n",
      "         std       0.99      0.96      0.98       726\n",
      "         ups       1.00      1.00      1.00       343\n",
      "         wlk       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           0.99      3276\n",
      "   macro avg       0.99      0.99      0.99      3276\n",
      "weighted avg       0.99      0.99      0.99      3276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(clf.predict([X_train, metadata_train]), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.75      0.68      0.71        75\n",
      "         jog       0.91      0.96      0.94        77\n",
      "         sit       0.98      0.98      0.98       210\n",
      "         std       0.97      0.97      0.97       174\n",
      "         ups       0.68      0.66      0.67        93\n",
      "         wlk       0.83      0.85      0.84       190\n",
      "\n",
      "    accuracy                           0.88       819\n",
      "   macro avg       0.85      0.85      0.85       819\n",
      "weighted avg       0.88      0.88      0.88       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(clf.predict([X_test, metadata_test]), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([sample for sample, _, _ in dataset])\n",
    "\n",
    "X_train = X[train_indices]\n",
    "X_test = X[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: {} (3276, 256, 12)\n",
      "y train shape: {} (3276, 6)\n",
      "X test shape: {} (819, 256, 12)\n",
      "y test shape: {} (819, 6)\n",
      "metdata train shape: {} (3276, 4, 1)\n",
      "metdata test shape: {} (819, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"X train shape: {}\", X_train.shape)\n",
    "print(\"y train shape: {}\", y_train.shape)\n",
    "print(\"X test shape: {}\", X_test.shape)\n",
    "print(\"y test shape: {}\", y_test.shape)\n",
    "print(\"metdata train shape: {}\", metadata_train.shape)\n",
    "print(\"metdata test shape: {}\", metadata_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "clf = Sequential()\n",
    "#add model layers\n",
    "clf.add(Conv1D(16, kernel_size=5, activation=\"relu\", input_shape=(256, 12)))\n",
    "clf.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
    "clf.add(Flatten())\n",
    "clf.add(Dense(6, activation=\"softmax\", kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 819 samples\n",
      "Epoch 1/30\n",
      "3276/3276 [==============================] - 1s 392us/step - loss: 1.1588 - accuracy: 0.5607 - val_loss: 0.8419 - val_accuracy: 0.7131\n",
      "Epoch 2/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.7115 - accuracy: 0.7579 - val_loss: 0.7180 - val_accuracy: 0.7521\n",
      "Epoch 3/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.6017 - accuracy: 0.8053 - val_loss: 0.7178 - val_accuracy: 0.7582\n",
      "Epoch 4/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.5390 - accuracy: 0.8303 - val_loss: 0.6707 - val_accuracy: 0.7827\n",
      "Epoch 5/30\n",
      "3276/3276 [==============================] - 1s 268us/step - loss: 0.5076 - accuracy: 0.8404 - val_loss: 0.7111 - val_accuracy: 0.7778\n",
      "Epoch 6/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.4931 - accuracy: 0.8452 - val_loss: 0.6275 - val_accuracy: 0.8230\n",
      "Epoch 7/30\n",
      "3276/3276 [==============================] - 1s 262us/step - loss: 0.4672 - accuracy: 0.8623 - val_loss: 0.5994 - val_accuracy: 0.8071\n",
      "Epoch 8/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.4491 - accuracy: 0.8614 - val_loss: 0.6473 - val_accuracy: 0.8132\n",
      "Epoch 9/30\n",
      "3276/3276 [==============================] - 1s 280us/step - loss: 0.4263 - accuracy: 0.8709 - val_loss: 0.5691 - val_accuracy: 0.8400\n",
      "Epoch 10/30\n",
      "3276/3276 [==============================] - 1s 269us/step - loss: 0.4021 - accuracy: 0.8883 - val_loss: 0.5817 - val_accuracy: 0.8059\n",
      "Epoch 11/30\n",
      "3276/3276 [==============================] - 1s 270us/step - loss: 0.3839 - accuracy: 0.8935 - val_loss: 0.6184 - val_accuracy: 0.8254\n",
      "Epoch 12/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.3856 - accuracy: 0.8849 - val_loss: 0.5681 - val_accuracy: 0.8254\n",
      "Epoch 13/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3595 - accuracy: 0.9026 - val_loss: 0.6096 - val_accuracy: 0.8364\n",
      "Epoch 14/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3580 - accuracy: 0.8944 - val_loss: 0.6040 - val_accuracy: 0.8474\n",
      "Epoch 15/30\n",
      "3276/3276 [==============================] - 1s 274us/step - loss: 0.3484 - accuracy: 0.9133 - val_loss: 0.5792 - val_accuracy: 0.8266\n",
      "Epoch 16/30\n",
      "3276/3276 [==============================] - 1s 271us/step - loss: 0.3616 - accuracy: 0.9005 - val_loss: 0.6682 - val_accuracy: 0.8144\n",
      "Epoch 17/30\n",
      "3276/3276 [==============================] - 1s 267us/step - loss: 0.3576 - accuracy: 0.9106 - val_loss: 0.5363 - val_accuracy: 0.8474\n",
      "Epoch 18/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.3303 - accuracy: 0.9154 - val_loss: 0.5681 - val_accuracy: 0.8474\n",
      "Epoch 19/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.3235 - accuracy: 0.9185 - val_loss: 0.5121 - val_accuracy: 0.8706\n",
      "Epoch 20/30\n",
      "3276/3276 [==============================] - 1s 266us/step - loss: 0.2961 - accuracy: 0.9277 - val_loss: 0.4885 - val_accuracy: 0.8755\n",
      "Epoch 21/30\n",
      "3276/3276 [==============================] - 1s 275us/step - loss: 0.2992 - accuracy: 0.9261 - val_loss: 0.5397 - val_accuracy: 0.8510\n",
      "Epoch 22/30\n",
      "3276/3276 [==============================] - 1s 272us/step - loss: 0.2949 - accuracy: 0.9261 - val_loss: 0.5308 - val_accuracy: 0.8645\n",
      "Epoch 23/30\n",
      "3276/3276 [==============================] - 1s 277us/step - loss: 0.2796 - accuracy: 0.9365 - val_loss: 0.5290 - val_accuracy: 0.8669\n",
      "Epoch 24/30\n",
      "3276/3276 [==============================] - 1s 264us/step - loss: 0.2738 - accuracy: 0.9374 - val_loss: 0.5396 - val_accuracy: 0.8584\n",
      "Epoch 25/30\n",
      "3276/3276 [==============================] - 1s 276us/step - loss: 0.3281 - accuracy: 0.9161 - val_loss: 0.5239 - val_accuracy: 0.8571\n",
      "Epoch 26/30\n",
      "3276/3276 [==============================] - 1s 271us/step - loss: 0.2905 - accuracy: 0.9393 - val_loss: 0.4680 - val_accuracy: 0.8840\n",
      "Epoch 27/30\n",
      "3276/3276 [==============================] - 1s 267us/step - loss: 0.2673 - accuracy: 0.9441 - val_loss: 0.4866 - val_accuracy: 0.8547\n",
      "Epoch 28/30\n",
      "3276/3276 [==============================] - 1s 265us/step - loss: 0.2501 - accuracy: 0.9475 - val_loss: 0.5122 - val_accuracy: 0.8694\n",
      "Epoch 29/30\n",
      "3276/3276 [==============================] - 1s 265us/step - loss: 0.2581 - accuracy: 0.9389 - val_loss: 0.4931 - val_accuracy: 0.8669\n",
      "Epoch 30/30\n",
      "3276/3276 [==============================] - 1s 273us/step - loss: 0.2725 - accuracy: 0.9350 - val_loss: 0.4698 - val_accuracy: 0.8742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x143f97350>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       1.00      0.99      0.99       284\n",
      "         jog       1.00      1.00      1.00       307\n",
      "         sit       0.87      0.97      0.91       794\n",
      "         std       0.96      0.84      0.89       726\n",
      "         ups       0.99      1.00      0.99       343\n",
      "         wlk       1.00      0.99      0.99       822\n",
      "\n",
      "    accuracy                           0.95      3276\n",
      "   macro avg       0.97      0.96      0.96      3276\n",
      "weighted avg       0.96      0.95      0.95      3276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(clf.predict(X_train), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.81      0.77      0.79        75\n",
      "         jog       0.96      0.95      0.95        77\n",
      "         sit       0.89      0.94      0.92       210\n",
      "         std       0.91      0.86      0.89       174\n",
      "         ups       0.76      0.69      0.72        93\n",
      "         wlk       0.86      0.91      0.88       190\n",
      "\n",
      "    accuracy                           0.87       819\n",
      "   macro avg       0.87      0.85      0.86       819\n",
      "weighted avg       0.87      0.87      0.87       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(clf.predict(X_test), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "conv = Sequential()\n",
    "# add model layers\n",
    "conv.add(Conv1D(16, kernel_size=5, activation=\"relu\", input_shape=(256, 3)))\n",
    "conv.add(Conv1D(32, kernel_size=5, activation=\"relu\"))\n",
    "conv.add(Flatten(name=\"coefs\"))\n",
    "\n",
    "metadata_input_tensor = Input(shape=(4, 1))\n",
    "metadata_input = Flatten(name=\"flatten\")(metadata_input_tensor)\n",
    "\n",
    "last_layer = conv.get_layer(\"coefs\").output\n",
    "x = concatenate([last_layer, metadata_input], axis=1)\n",
    "out = Dense(6, activation=\"softmax\")(x)\n",
    "\n",
    "clf = Model([conv.input, metadata_input_tensor], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 819 samples\n",
      "Epoch 1/30\n",
      "3276/3276 [==============================] - 1s 374us/step - loss: 0.9303 - accuracy: 0.6242 - val_loss: 0.6766 - val_accuracy: 0.7436\n",
      "Epoch 2/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.5016 - accuracy: 0.7866 - val_loss: 0.5411 - val_accuracy: 0.7753\n",
      "Epoch 3/30\n",
      "3276/3276 [==============================] - 1s 307us/step - loss: 0.3788 - accuracy: 0.8483 - val_loss: 0.5021 - val_accuracy: 0.8010\n",
      "Epoch 4/30\n",
      "3276/3276 [==============================] - 1s 302us/step - loss: 0.2967 - accuracy: 0.8886 - val_loss: 0.4907 - val_accuracy: 0.8291\n",
      "Epoch 5/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.2517 - accuracy: 0.9106 - val_loss: 0.4769 - val_accuracy: 0.8535\n",
      "Epoch 6/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.2101 - accuracy: 0.9216 - val_loss: 0.4639 - val_accuracy: 0.8474\n",
      "Epoch 7/30\n",
      "3276/3276 [==============================] - 1s 311us/step - loss: 0.1692 - accuracy: 0.9426 - val_loss: 0.4234 - val_accuracy: 0.8632\n",
      "Epoch 8/30\n",
      "3276/3276 [==============================] - 1s 308us/step - loss: 0.1367 - accuracy: 0.9554 - val_loss: 0.4549 - val_accuracy: 0.8718\n",
      "Epoch 9/30\n",
      "3276/3276 [==============================] - 1s 317us/step - loss: 0.1263 - accuracy: 0.9606 - val_loss: 0.4667 - val_accuracy: 0.8706\n",
      "Epoch 10/30\n",
      "3276/3276 [==============================] - 1s 320us/step - loss: 0.1088 - accuracy: 0.9631 - val_loss: 0.4835 - val_accuracy: 0.8718\n",
      "Epoch 11/30\n",
      "3276/3276 [==============================] - 1s 316us/step - loss: 0.0996 - accuracy: 0.9667 - val_loss: 0.5491 - val_accuracy: 0.8584\n",
      "Epoch 12/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 0.4904 - val_accuracy: 0.8730\n",
      "Epoch 13/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0836 - accuracy: 0.9698 - val_loss: 0.4876 - val_accuracy: 0.8730\n",
      "Epoch 14/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.0689 - accuracy: 0.9780 - val_loss: 0.5143 - val_accuracy: 0.8669\n",
      "Epoch 15/30\n",
      "3276/3276 [==============================] - 1s 317us/step - loss: 0.0649 - accuracy: 0.9783 - val_loss: 0.5318 - val_accuracy: 0.8755\n",
      "Epoch 16/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0652 - accuracy: 0.9780 - val_loss: 0.5435 - val_accuracy: 0.8742\n",
      "Epoch 17/30\n",
      "3276/3276 [==============================] - 1s 306us/step - loss: 0.0583 - accuracy: 0.9814 - val_loss: 0.5484 - val_accuracy: 0.8742\n",
      "Epoch 18/30\n",
      "3276/3276 [==============================] - 1s 305us/step - loss: 0.0624 - accuracy: 0.9759 - val_loss: 0.6054 - val_accuracy: 0.8718\n",
      "Epoch 19/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.0557 - accuracy: 0.9805 - val_loss: 0.6509 - val_accuracy: 0.8742\n",
      "Epoch 20/30\n",
      "3276/3276 [==============================] - 1s 321us/step - loss: 0.0832 - accuracy: 0.9731 - val_loss: 0.5975 - val_accuracy: 0.8755\n",
      "Epoch 21/30\n",
      "3276/3276 [==============================] - 1s 313us/step - loss: 0.1017 - accuracy: 0.9631 - val_loss: 0.7383 - val_accuracy: 0.8596\n",
      "Epoch 22/30\n",
      "3276/3276 [==============================] - 1s 310us/step - loss: 0.0685 - accuracy: 0.9762 - val_loss: 0.5572 - val_accuracy: 0.8730\n",
      "Epoch 23/30\n",
      "3276/3276 [==============================] - 1s 309us/step - loss: 0.0477 - accuracy: 0.9829 - val_loss: 0.5575 - val_accuracy: 0.8864\n",
      "Epoch 24/30\n",
      "3276/3276 [==============================] - 1s 307us/step - loss: 0.0498 - accuracy: 0.9820 - val_loss: 0.5860 - val_accuracy: 0.8840\n",
      "Epoch 25/30\n",
      "3276/3276 [==============================] - 1s 319us/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.5857 - val_accuracy: 0.8828\n",
      "Epoch 26/30\n",
      "3276/3276 [==============================] - 1s 308us/step - loss: 0.0353 - accuracy: 0.9884 - val_loss: 0.6012 - val_accuracy: 0.8877\n",
      "Epoch 27/30\n",
      "3276/3276 [==============================] - 1s 345us/step - loss: 0.0365 - accuracy: 0.9884 - val_loss: 0.6133 - val_accuracy: 0.8877\n",
      "Epoch 28/30\n",
      "3276/3276 [==============================] - 1s 315us/step - loss: 0.0457 - accuracy: 0.9832 - val_loss: 0.6123 - val_accuracy: 0.8828\n",
      "Epoch 29/30\n",
      "3276/3276 [==============================] - 1s 314us/step - loss: 0.0371 - accuracy: 0.9850 - val_loss: 0.6443 - val_accuracy: 0.8852\n",
      "Epoch 30/30\n",
      "3276/3276 [==============================] - 1s 312us/step - loss: 0.0365 - accuracy: 0.9860 - val_loss: 0.6552 - val_accuracy: 0.8816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x122d27d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit([X_train, metadata_train], y_train, validation_data=([X_test, metadata_test], y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       1.00      1.00      1.00       284\n",
      "         jog       1.00      1.00      1.00       307\n",
      "         sit       0.97      0.99      0.98       794\n",
      "         std       0.99      0.96      0.98       726\n",
      "         ups       1.00      1.00      1.00       343\n",
      "         wlk       1.00      1.00      1.00       822\n",
      "\n",
      "    accuracy                           0.99      3276\n",
      "   macro avg       0.99      0.99      0.99      3276\n",
      "weighted avg       0.99      0.99      0.99      3276\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(clf.predict([X_train, metadata_train]), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.75      0.68      0.71        75\n",
      "         jog       0.91      0.96      0.94        77\n",
      "         sit       0.98      0.98      0.98       210\n",
      "         std       0.97      0.97      0.97       174\n",
      "         ups       0.68      0.66      0.67        93\n",
      "         wlk       0.83      0.85      0.84       190\n",
      "\n",
      "    accuracy                           0.88       819\n",
      "   macro avg       0.85      0.85      0.85       819\n",
      "weighted avg       0.88      0.88      0.88       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(clf.predict([X_test, metadata_test]), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "X = np.array([sample[:,-3:] for sample, _, _ in dataset])\n",
    "\n",
    "X_train, y_train = X[train_indices], y[train_indices]\n",
    "X_test, y_test = X[test_indices], y[test_indices]\n",
    "metadata_train = metadata[train_indices]\n",
    "metadata_test = metadata[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create model\n",
    "clf = Sequential()\n",
    "#add model layers\n",
    "clf.add(LSTM(128, input_shape=(256, 3)))\n",
    "clf.add(Dense(6, activation=\"softmax\", kernel_regularizer=keras.regularizers.l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3276 samples, validate on 819 samples\n",
      "Epoch 1/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.6347 - accuracy: 0.3495 - val_loss: 1.5116 - val_accuracy: 0.4322\n",
      "Epoch 2/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.1245 - accuracy: 0.5256 - val_loss: 0.9684 - val_accuracy: 0.5592\n",
      "Epoch 3/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.3953 - accuracy: 0.4359 - val_loss: 1.2896 - val_accuracy: 0.4737\n",
      "Epoch 4/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.2004 - accuracy: 0.5015 - val_loss: 1.2714 - val_accuracy: 0.4713\n",
      "Epoch 5/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.1137 - accuracy: 0.4973 - val_loss: 1.0797 - val_accuracy: 0.5250\n",
      "Epoch 6/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.0063 - accuracy: 0.5598 - val_loss: 1.2686 - val_accuracy: 0.5531\n",
      "Epoch 7/30\n",
      "3276/3276 [==============================] - 27s 8ms/step - loss: 1.2043 - accuracy: 0.5046 - val_loss: 1.2719 - val_accuracy: 0.4103\n",
      "Epoch 8/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.1634 - accuracy: 0.4881 - val_loss: 1.1766 - val_accuracy: 0.4432\n",
      "Epoch 9/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.0627 - accuracy: 0.4948 - val_loss: 1.0601 - val_accuracy: 0.4860\n",
      "Epoch 10/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.3716 - accuracy: 0.4307 - val_loss: 1.4146 - val_accuracy: 0.4164\n",
      "Epoch 11/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.4192 - accuracy: 0.4154 - val_loss: 1.3607 - val_accuracy: 0.4762\n",
      "Epoch 12/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.3604 - accuracy: 0.4472 - val_loss: 1.3967 - val_accuracy: 0.4310\n",
      "Epoch 13/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.4154 - accuracy: 0.4203 - val_loss: 1.4044 - val_accuracy: 0.4359\n",
      "Epoch 14/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.3552 - accuracy: 0.4353 - val_loss: 1.3486 - val_accuracy: 0.4554\n",
      "Epoch 15/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.3743 - accuracy: 0.4231 - val_loss: 1.3396 - val_accuracy: 0.4896\n",
      "Epoch 16/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.3062 - accuracy: 0.4679 - val_loss: 1.2995 - val_accuracy: 0.4457\n",
      "Epoch 17/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.2895 - accuracy: 0.4698 - val_loss: 1.2796 - val_accuracy: 0.4847\n",
      "Epoch 18/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.2515 - accuracy: 0.4789 - val_loss: 1.2560 - val_accuracy: 0.5067\n",
      "Epoch 19/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.2430 - accuracy: 0.4902 - val_loss: 1.2223 - val_accuracy: 0.5067\n",
      "Epoch 20/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.2487 - accuracy: 0.4866 - val_loss: 1.2774 - val_accuracy: 0.4420\n",
      "Epoch 21/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.2869 - accuracy: 0.4640 - val_loss: 1.2438 - val_accuracy: 0.5043\n",
      "Epoch 22/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.2785 - accuracy: 0.4954 - val_loss: 1.2899 - val_accuracy: 0.4872\n",
      "Epoch 23/30\n",
      "3276/3276 [==============================] - 26s 8ms/step - loss: 1.2837 - accuracy: 0.4679 - val_loss: 1.2761 - val_accuracy: 0.4872\n",
      "Epoch 24/30\n",
      "3276/3276 [==============================] - 25s 8ms/step - loss: 1.2692 - accuracy: 0.4823 - val_loss: 1.2672 - val_accuracy: 0.4969\n",
      "Epoch 25/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2717 - accuracy: 0.4795 - val_loss: 1.2336 - val_accuracy: 0.4969\n",
      "Epoch 26/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2694 - accuracy: 0.4814 - val_loss: 1.2602 - val_accuracy: 0.4982\n",
      "Epoch 27/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2909 - accuracy: 0.4679 - val_loss: 1.2549 - val_accuracy: 0.4750\n",
      "Epoch 28/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2862 - accuracy: 0.4545 - val_loss: 1.2757 - val_accuracy: 0.4347\n",
      "Epoch 29/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2771 - accuracy: 0.4600 - val_loss: 1.2441 - val_accuracy: 0.4969\n",
      "Epoch 30/30\n",
      "3276/3276 [==============================] - 24s 7ms/step - loss: 1.2296 - accuracy: 0.5061 - val_loss: 1.5277 - val_accuracy: 0.4322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1253aeb50>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.00      0.00      0.00       284\n",
      "         jog       1.00      0.28      0.44       307\n",
      "         sit       0.35      1.00      0.52       794\n",
      "         std       0.00      0.00      0.00       726\n",
      "         ups       0.00      0.00      0.00       343\n",
      "         wlk       0.57      0.65      0.61       822\n",
      "\n",
      "    accuracy                           0.43      3276\n",
      "   macro avg       0.32      0.32      0.26      3276\n",
      "weighted avg       0.32      0.43      0.32      3276\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sergio/PycharmProjects/MLEARN/venv/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_train, axis=1), np.argmax(clf.predict(X_train), axis=1), target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         dws       0.00      0.00      0.00        75\n",
      "         jog       1.00      0.19      0.33        77\n",
      "         sit       0.37      1.00      0.54       210\n",
      "         std       0.00      0.00      0.00       174\n",
      "         ups       0.00      0.00      0.00        93\n",
      "         wlk       0.53      0.68      0.60       190\n",
      "\n",
      "    accuracy                           0.43       819\n",
      "   macro avg       0.32      0.31      0.24       819\n",
      "weighted avg       0.31      0.43      0.31       819\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(y_test, axis=1), np.argmax(clf.predict(X_test), axis=1), target_names=label_encoder.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
